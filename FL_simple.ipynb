{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "fMokd9tWq-Zf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o conjunto de dados NSL-KDD\n",
        "\n",
        "!wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\n",
        "!gzip -d kddcup.data_10_percent.gz\n"
      ],
      "metadata": {
        "id": "bnfdfO12TJBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b46c4d-75ec-40a7-d2e0-cb9440afac9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-08 00:42:57--  http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\n",
            "Resolving kdd.ics.uci.edu (kdd.ics.uci.edu)... 128.195.1.86\n",
            "Connecting to kdd.ics.uci.edu (kdd.ics.uci.edu)|128.195.1.86|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2144903 (2.0M) [application/x-gzip]\n",
            "Saving to: ‘kddcup.data_10_percent.gz’\n",
            "\n",
            "kddcup.data_10_perc 100%[===================>]   2.04M  1.86MB/s    in 1.1s    \n",
            "\n",
            "2024-02-08 00:42:58 (1.86 MB/s) - ‘kddcup.data_10_percent.gz’ saved [2144903/2144903]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/KDDTrain+.txt')"
      ],
      "metadata": {
        "id": "6S8uv1xaTh4l"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir as colunas\n",
        "columns = np.array([\n",
        "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
        "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
        "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
        "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
        "    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate',\n",
        "    'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
        "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
        "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
        "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
        "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'\n",
        "])"
      ],
      "metadata": {
        "id": "4T0ELo3vV6QN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar os dados\n",
        "#data = np.genfromtxt('KDDTrain+.txt', delimiter=',')\n",
        "data = np.genfromtxt('/content/KDDTrain+.txt', delimiter=',')\n",
        "X = data[:, :-1]\n",
        "y_str = data[:, -1].astype(object)"
      ],
      "metadata": {
        "id": "L_F7Ztr1V9Aq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "ShQ15unkbPks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b3f0a20-18ce-4124-fa33-7be75531231c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0., nan, nan, ...,  0., nan, 20.],\n",
              "       [ 0., nan, nan, ...,  0., nan, 15.],\n",
              "       [ 0., nan, nan, ...,  0., nan, 19.],\n",
              "       ...,\n",
              "       [ 0., nan, nan, ...,  0., nan, 18.],\n",
              "       [ 0., nan, nan, ...,  0., nan, 20.],\n",
              "       [ 0., nan, nan, ...,  0., nan, 21.]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pré-processamento dos dados\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa5TyzjbXofW",
        "outputId": "11b296db-2c0e-41b7-fd73-5868f3aac5c7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1047: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1052: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1072: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificação one-hot para variáveis categóricas\n",
        "X_encoded = np.zeros((X.shape[0], X.shape[1] + 3))\n",
        "for i in range(X.shape[1]):\n",
        "    if i not in [1, 2, 3]:  # As colunas 1, 2 e 3 são variáveis categóricas\n",
        "        X_encoded[:, i] = X_scaled[:, i]\n",
        "    else:\n",
        "        unique_values = np.unique(X[:, i])\n",
        "        for j, value in enumerate(unique_values):\n",
        "            X_encoded[:, j + X.shape[1]] = (X[:, i] == value).astype(int)"
      ],
      "metadata": {
        "id": "LeAnlJrEXsM6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificar os rótulos\n",
        "labels = np.unique(y_str)\n",
        "y_encoded = np.array([np.where(labels == label)[0][0] for label in y_str])"
      ],
      "metadata": {
        "id": "d363OiicXxED"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "9-FYNOGxXyOg"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbKeorHHP0Dd",
        "outputId": "63fd82a0-a30d-4915-c9e8-69e6182a7fe1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1047: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1052: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1072: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura do modelo\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(labels), activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "98WYhTAbX3Eo"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar o modelo\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qZxKsIpYX6Gr"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5tGNRw66qJs",
        "outputId": "6dc64dc6-e787-4af8-a2e4-1fd645ff44b6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25195, 45)\n",
            "(25195,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo localmente\n",
        "model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B_xoZqKX7xE",
        "outputId": "2245bf38-93c3-4b9a-9651-376b36c9568a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "3150/3150 [==============================] - 4s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 2/25\n",
            "3150/3150 [==============================] - 5s 2ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 3/25\n",
            "3150/3150 [==============================] - 4s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 4/25\n",
            "3150/3150 [==============================] - 5s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 5/25\n",
            "3150/3150 [==============================] - 5s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 6/25\n",
            "3150/3150 [==============================] - 5s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 7/25\n",
            "3150/3150 [==============================] - 5s 2ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 8/25\n",
            "3150/3150 [==============================] - 4s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 9/25\n",
            "3150/3150 [==============================] - 4s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 10/25\n",
            "3150/3150 [==============================] - 5s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 11/25\n",
            "3150/3150 [==============================] - 4s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 12/25\n",
            "3150/3150 [==============================] - 5s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 13/25\n",
            "3150/3150 [==============================] - 4s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 14/25\n",
            "3150/3150 [==============================] - 5s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 15/25\n",
            "3150/3150 [==============================] - 5s 2ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 16/25\n",
            "3150/3150 [==============================] - 4s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 17/25\n",
            "3150/3150 [==============================] - 4s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 18/25\n",
            "3150/3150 [==============================] - 5s 2ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 19/25\n",
            "3150/3150 [==============================] - 5s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 20/25\n",
            "3150/3150 [==============================] - 5s 2ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 21/25\n",
            "3150/3150 [==============================] - 4s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 22/25\n",
            "3150/3150 [==============================] - 5s 2ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 23/25\n",
            "3150/3150 [==============================] - 5s 2ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 24/25\n",
            "3150/3150 [==============================] - 4s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n",
            "Epoch 25/25\n",
            "3150/3150 [==============================] - 5s 1ms/step - loss: nan - accuracy: 4.9614e-04 - val_loss: nan - val_accuracy: 6.3505e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b57bae18f70>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para dividir os dados em shards\n",
        "def create_shards(X, y, num_clients):\n",
        "    X_shards, y_shards = [], []\n",
        "    X, y = shuffle(X, y)\n",
        "    shard_size = len(X) // num_clients\n",
        "    for i in range(num_clients):\n",
        "        start = i * shard_size\n",
        "        end = (i + 1) * shard_size if i < num_clients - 1 else len(X)\n",
        "        X_shards.append(X[start:end])\n",
        "        y_shards.append(y[start:end])\n",
        "    return X_shards, y_shards"
      ],
      "metadata": {
        "id": "ooxpmM06X9vU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configurações do Federated Learning\n",
        "num_clients = 5\n",
        "num_rounds = 10\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "tTNRgIw_X_Zo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados em shards para os clientes\n",
        "X_shards, y_shards = create_shards(X_train, y_train, num_clients)"
      ],
      "metadata": {
        "id": "FIwkeYgYYBw0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "8DCyoUW1q36r",
        "outputId": "d2d71e65-db1b-4a65-dbb6-0150e5dc255a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1/10\n",
            "\tClient 1/5\n",
            "\tClient 2/5\n",
            "\tClient 3/5\n",
            "\tClient 4/5\n",
            "\tClient 5/5\n",
            "\tEvaluating global model\n",
            "\tRound 1 Accuracy: 0.0006350466283038259\n",
            "Round 2/10\n",
            "\tClient 1/5\n",
            "\tClient 2/5\n",
            "\tClient 3/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-5f4ef759c332>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mclient_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tEvaluating global model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\tRound {round_num + 1} Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m         )\n\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_gradients_aggregation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36maggregate_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_reduce_sum_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     def apply_gradients(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/utils.py\u001b[0m in \u001b[0;36mall_reduce_sum_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_grads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             reduced = tf.distribute.get_replica_context().all_reduce(\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceOp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mall_reduce\u001b[0;34m(self, reduce_op, value, options)\u001b[0m\n\u001b[1;32m   3647\u001b[0m         \u001b[0;31m# The gradient of an all-sum is itself an all-sum (all-mean, likewise).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdy_s\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3649\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflattened_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3650\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3651\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhas_indexed_slices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(wrapped, args, kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;34m\"\"\"Decorated function with custom gradient.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_eager_mode_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_graph_mode_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36m_eager_mode_decorator\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m       nest.flatten(result))\n\u001b[1;32m    565\u001b[0m   \u001b[0;31m# TODO(apassos) consider removing the identity below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m   \u001b[0mflat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m   input_tensors = [\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/custom_gradient.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    564\u001b[0m       nest.flatten(result))\n\u001b[1;32m    565\u001b[0m   \u001b[0;31m# TODO(apassos) consider removing the identity below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m   \u001b[0mflat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m   input_tensors = [\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4182\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4183\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4184\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   4185\u001b[0m         _ctx, \"Identity\", name, input)\n\u001b[1;32m   4186\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# Iniciar o treinamento federado\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "    for client in range(num_clients):\n",
        "        print(f\"\\tClient {client + 1}/{num_clients}\")\n",
        "        model_weights = model.get_weights()\n",
        "        client_X, client_y = X_shards[client], y_shards[client]\n",
        "        client_dataset = tf.data.Dataset.from_tensor_slices((client_X, client_y)).shuffle(len(client_X)).batch(batch_size)\n",
        "        client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "        for X_batch, y_batch in client_dataset:\n",
        "            with tf.GradientTape() as tape:\n",
        "                y_pred = model(X_batch)\n",
        "                loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_pred)\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            client_optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    print(\"\\tEvaluating global model\")\n",
        "    print(f\"\\tRound {round_num + 1} Accuracy:\", model.evaluate(X_test, y_test, verbose=0)[1])\n",
        "\n",
        "print(\"Federated Learning Finished\")\n"
      ]
    }
  ]
}